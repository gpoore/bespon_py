# -*- coding: utf-8 -*-
#
# Copyright (c) 2016, Geoffrey M. Poore
# All rights reserved.
#
# Licensed under the BSD 3-Clause License:
# http://opensource.org/licenses/BSD-3-Clause
#


from __future__ import (division, print_function, absolute_import,
                        unicode_literals)


from .version import __version__
import sys

if sys.version_info.major == 2:
    str = unicode
    __chr__ = chr
    chr = unichr

from . import erring
from . import unicoding
import collections
import binascii
import base64




class Source(object):
    '''
    Keep track of the name of a source (file name, or <string>), and of the
    current location within the source (range of lines currently being parsed).

    An instance is created when decoding begins, and line numbers are updated
    as parsing proceedsd.  The source instance is passed on to any parsing
    errors that are raised, to provide informative error messages.
    '''
    def __init__(self, name=None, start_lineno=0, end_lineno=0):
        if name is None:
            name = '<string>'
        self.name = name
        self.start_lineno = start_lineno
        self.end_lineno = end_lineno


class AstObj(list):
    '''
    Abstract representation of collection types in AST.

    At parse time, the type of a collection typically isn't known.  `AstObj`
    instances automatically determine their own type, and enforce it, based
    on the types that are appended to them.

    Attributes:
      +  cat          = General type category of the object.  Typically starts as
                        `None`, and becomes `list` (list-like; list, set, etc.),
                        `dict` (dict-like; dict, ordered dict, or other mapping),
                        or `kvpair` (key-value pair; what an object with category
                        `dict` must contain)
      +  closechar    = Character expected for closing the current object.  An
                        object opened in non-compact form cannot be closed by
                        parentheses.  An object opened with a fullwidth
                        parenthesis must be closed by one.
      +  nodetype     = The actual type of the object.  Typically starts as
                        `None`, except for objects with explicit typing via
                        `(type)>` syntax.
      +  source       = A `Source` instance, used for providing line numbers in
                        any error messages generated by attempting to append
                        invalid types.
      +  start_lineno = Line number on which object started.  Used for
                        providing line error information for instances that
                        were never closed.
    '''
    __slots__ = ['cat', 'closechar', 'nodetype', 'source', 'start_lineno']
    def __init__(self, nodetype=None, cat=None, source=None, openchar=None):
        self.nodetype = nodetype
        self.cat = cat
        closechar_dict = {'(': ')', '\uFF08': '\uFF09', None: None}
        self.closechar = closechar_dict[openchar]
        self.source = source
        if source is None:
            self.start_lineno = None
        else:
            self.start_lineno = source.start_lineno
        # Never instantiated with any contents
        list.__init__(self)
    def check_append(self, val):
        '''
        Append a value, making sure that the value is consistent with the type
        of the instance, or deriving the type of the instance from the value
        if the instance's type is not yet known.
        '''
        if isinstance(val, AstObj):
            if self.cat is None:
                # The only category that is guaranteed to be known at parse
                # time is `kvpair`, and that's enough to distinguish `dict`
                # from `list`
                if val.cat == 'kvpair':
                    self.cat = 'dict'
                else:
                    self.cat = 'list'
            if not (self.cat == 'list' or (self.cat == 'dict' and val.cat == 'kvpair') or (self.cat == 'kvpair' and len(self) == 1)):
                raise erring.ParseError('Attempting to add a collection object where one is not allowed', self.source)
        elif self.cat is None:
            self.cat = 'list'
        self.append(val)


class RootAstObj(AstObj):
    '''
    Root of AST.  May only contain a single object.
    '''
    __slots__ = ['cat', 'closechar', 'nodetype', 'source', 'start_lineno']
    def __init__(self, source=None):
        self.cat = '(root)'
        self.closechar = None
        self.nodetype = '(root)'
        self.source = source
        if source is None:
            self.start_lineno = None
        else:
            self.start_lineno = source.start_lineno
        # Never instantiated with any contents
        list.__init__(self)
    def check_append(self, val):
        if len(self) == 1:
            raise erring.ParseError('Only a single scalar or collection type is allowed at root level', self.source)
        self.append(val)




class BespONDecoder(object):
    '''
    Decode BespON.

    Works with Unicode strings or iterables containing Unicode strings.
    '''
    def __init__(self, reserved_words=None, parsers=None, aliases=None, **kwargs):
        # If a `Source()` instance is provided, enhanced tracebacks are
        # possible in some cases.  Start with default value.  An actual
        # instance is created at the beginning of decoding.
        self.source = None


        # Basic type checking on arguments
        arg_dicts = (reserved_words, parsers, aliases)
        if not all(x is None or isinstance(x, dict) for x in arg_dicts):
            raise TypeError('Arguments {0} must be dicts'.format(', '.join('"{0}"'.format(x) for x in arg_dicts)))
        if parsers:
            if not all(hasattr(v, '__call__') for k, v in parsers.items()):
                raise TypeError('All parsers must be functions (callable)')
            if any(k.lower() in ('bool', 'null', 'inf', '+inf', '-inf', 'nan') for k in parsers):
                raise ValueError('Parsing of bool, null, inf, and nan is managed via "reserved_words"')


        # Defaults
        self.default_reserved_words = {'true': True, 'false': False, 'null': None,
                                       'inf': float('inf'), '-inf': float('-inf'), '+inf': float('+inf'),
                                       'nan': float('nan')}

        self.default_parsers = {#Basic types
                                'dict':        dict,
                                'list':        list,
                                'float':       float,
                                'int':         int,
                                'str':         self.parse_str,
                                #Extended types
                                'str.empty':   self.parse_str_empty,
                                'str.esc':     self.parse_str_esc,
                                #Optional types
                                'bin':         self.parse_bin,
                                'bin.empty':   self.parse_bin_empty,
                                'bin.esc':     self.parse_bin_esc,
                                'bin.base64':  self.parse_bin_base64,
                                'bin.hex':     self.parse_bin_base16,
                                'odict':       collections.OrderedDict,
                                'set':         set,
                                'tuple':       tuple,}

        self.default_aliases = {'esc': 'str.esc', 'bin.b64': 'bin.base64',
                                'bin.b16': 'bin.base16', 'bin.hex': 'bin.base16'}


        # Create actual dicts that are used
        self.reserved_words = self.default_reserved_words.copy()
        if reserved_words:
            self.reserved_words.update(reserved_words)

        self.parsers = self.default_parsers.copy()
        if parsers:
            self.parsers.update(parsers)

        self.aliases = self.default_aliases.copy()
        if aliases:
            for k, v in aliases.items():
                if v not in self.parsers:
                    raise ValueError('Alias "{0}" => "{1}" maps to unknown type'.format(k, v))
                self.parsers[k] = self.parsers[v]


        # Create a UnicodeFilter instance
        # Provide shortcuts to some of its attributes
        self.unicodefilter = unicoding.UnicodeFilter(**kwargs)
        self.newlines = self.unicodefilter.newlines
        self.newline_chars = self.unicodefilter.newline_chars
        self.newline_chars_str = self.unicodefilter.newline_chars_str
        self.spaces = self.unicodefilter.spaces
        self.spaces_str = self.unicodefilter.spaces_str
        self.indents = self.unicodefilter.indents
        self.indents_str = self.unicodefilter.indents_str
        self.whitespace = self.unicodefilter.whitespace
        self.whitespace_str = self.unicodefilter.whitespace_str

        # Create dicts used in parsing
        # It's convenient to define these next to the definition of the
        # functions they contain
        self._build_parsing_dicts_and_re()


    def _unwrap_inline(self, s_list):
        '''
        Unwrap an inline string.

        Any line that ends with a newline preceded by spaces (space or
        ideographic space) has the newline stripped.  Otherwise, a trailing
        newline is replace by a space.  The last line will not have a newline,
        and any trailing whitespace it has will already have been dealt with
        during parsing, so it is passed through unmodified.
        '''
        s_list_inline = []
        newline_chars_str = self.newline_chars_str
        spaces_str = self.spaces_str
        for line in s_list[:-1]:
            line_strip_nl = line.rstrip(newline_chars_str)
            if line_strip_nl.rstrip(spaces_str) != line_strip_nl:
                s_list_inline.append(line_strip_nl)
            else:
                s_list_inline.append(line_strip_nl + '\x20')
        s_list_inline.append(s_list[-1])
        return ''.join(s_list_inline)


    def parse_str(self, s_list, inline=False):
        '''
        Return a formatted string.

        Receives a list of strings, including newlines, and returns a string.

        Note that this function receives the raw result of parsing.  Any
        non-string indentation has already been stripped.  For unquoted
        strings, any leading/trailing indentation characters and newlines
        have also been stripped/handled.  All other newlines have not been
        handled; any unwrapping for inline strings remains to be done.
        '''
        if inline:
            s = self._unwrap_inline(s_list)
        else:
            s = ''.join(s_list)
        return s


    def parse_str_empty(self, s_list, inline=False):
        '''
        Return an empty string.
        '''
        s = self.parse_str(s_list, inline)
        if s:
            raise erring.ParseError('Explicitly typed empty string is not really empty', self.source)
        return s



    def parse_str_esc(self, s_list, inline=False):
        '''
        Return an unescaped version of a string.
        '''
        return self.unicodefilter.unescape(self.parse_str(s_list, inline))


    def parse_bin(self, s_list, inline=False):
        '''
        Return a binary string.
        '''
        if inline:
            s = self._unwrap_inline(s_list)
        else:
            s = ''.join(s_list)
        # If there are Unicode newline characters, convert them to `\n`
        s = self.unicodefilter.unicode_to_bin_newlines(s)
        try:
            b = s.encode('ascii')
        except UnicodeEncodeError as e:
            raise erring.BinaryStringEncodeError(s, e, self.source)
        return b


    def parse_bin_empty(self, s_list, inline=False):
        '''
        Return an empty string.
        '''
        b = self.parse_bin(s_list, inline)
        if b:
            raise erring.ParseError('Explicitly typed empty binary string is not really empty', self.source)
        return b


    def parse_bin_esc(self, s_list, inline=False):
        '''
        Return an unescaped version of a binary string.
        '''
        b = self.parse_bin(s_list, inline)
        return self.unicodefilter.unescape_bin(b)


    def parse_bin_base64(self, s_list, inline=False):
        '''
        Return a base64-decoded byte string.
        '''
        s = ''.join(s_list)
        s = self.unicodefilter.remove_whitespace(s)
        try:
            b = base64.b64decode(s)
        except  (ValueError, TypeError, UnicodeEncodeError, binascii.Error) as e:
            raise erring.BinaryBase64DecodeError(s, e, self.source)
        return b


    def parse_bin_base16(self, s_list, inline=False):
        '''
        Return a byte string from hex decoding.
        '''
        s = ''.join(s_list)
        s = self.unicodefilter.remove_whitespace(s)
        try:
            b = base64.b16decode(s)
        except (ValueError, TypeError, UnicodeEncodeError, binascii.Error) as e:
            raise erring.BinaryBase16DecodeError(s, e, self.source)
        return b


    def decode(self, s):
        '''
        Decode a Unicode string into objects.
        '''
        if not isinstance(s, str):
            raise ValueError('BespONDecoder only decodes Unicode strings')

        # Check for characters that may not appear literally
        if self.unicodefilter.has_nonliterals(s):
            trace = self.unicodefilter.trace_nonliterals(s)
            msg = '\n' + self.unicodefilter.format_nonliterals_trace(trace)
            raise erring.InvalidLiteralCharacterError(msg)

        # Create a Source() instance for tracking parsing location and
        # providing informative error messages.  Pass it to UnicodeFilter()
        # instance so that it can use it as well.
        self.source = Source()
        self.unicodefilter.source = self.source

        # Create a generator for lines from the source, keeping newlines
        # Then parse to AST, and convert AST to Python objects
        self._line_gen = (line for line in s.splitlines(True))
        self._parse_lines_to_ast()
        #self._parse_ast_to_pyobj()

        # Clean up Source() instance.  Don't want it hanging around in case
        # the decoder instance or its methods are used again.
        self.source = None
        self.unicodefilter.source = None

        # return self._pyobj


    def _parse_lines_to_ast(self):
        '''
        Process lines from source into abstract syntax tree (AST).

        All collection types are represented as `AstObj` instances.  These
        will later be processed into actual dicts, lists, ordered dicts, sets,
        and so on.

        All other other objects appear in the AST as literals (null, bool,
        string, binary, int, float, etc.).  They are processed into final form
        during this stage of the parsing.

        Since the same style of delimiting is used for all collection types,
        including lists and dicts, we typically don't know the type of a
        collection object when creating an `AstObj`.  The solution is that
        the `AstObj` has built-in logic that determines its own type, on the
        fly, based on what it contains (what is appended to it).  An `AstObj`
        will raise an error if there is an attempt to add something that
        disagrees with its self-determined type.

        Note that the root node of the AST is a `RootAstObj` instance.  This
        is an `AstObj` subclass that may only contain a single object.  At
        the root level, a BespON file may only contain a single scalar, or a
        single collection type.
        '''
        self._ast = RootAstObj(source=self.source)
        self._ast_pos = self._ast
        self._ast_pos_stack = []
        self._next_type = None
        self._indent = ''
        self._indent_stack = []
        self._in_compact = False
        self._in_compact_stack = []

        # Get things started by extracting the first line (if any), stripping
        # any BOM, and setting the line to `None` if it would have been `None`
        # had the BOM been removed before this stage.  Essentially, a file
        # will be treated as empty (producing no output) unless it contains
        # at least newlines.
        line = self._parse_line_goto_next('')
        if line is not None:
            line = self._drop_bom(line)
            if not line:
                line = None

        while line is not None:
            # Using line[:1] gives '' for empty string; no IndexError
            line = self._parse_line[line[:1]](line)
            if not self._ast:
                self._ast_pos.append('')


    def _drop_bom(self, s):
        '''
        Handle any BOMs.

        Note that at this point, after the string is already in memory, we
        can't do anything general about the possibility of UTF-32 BOMs.
        UTF-32BE is `\\U0000FEFF`, which at this point can't be distinguished
        from UTF-16BE.  `\\uFEFF` is dropped, so both cases are handled.  If
        the UTF-32BE case is read incorrectly as UTF-16BE, then there will be
        null bytes, which are not allowed as literals by default.  Python
        won't allow `\\UFFFE0000`, which is the UTF-32LE BOM, so that case
        isn't an issue either.
        '''
        BOM = {'UTF-8': '\xEF\xBB\xBF',
               'UTF-16BE/UTF-32BE': '\uFEFF',
               'UTF-16LE': '\uFFFE'}
        encs = []
        for enc, chars in BOM.items():
            if s.startswith(chars):
                s = s[len(chars):]
                encs.append(enc)
        # Check for double BOMs just for fun
        for enc, chars in BOM.items():
            if s.startswith(chars):
                s = s[len(chars):]
                encs.append(enc)
        if len(encs) > 1:
            raise ValueError('Encountered BOM for multiple encodings {0}'.format(', '.join(e for e in encs)))
        return s


    def _split_line_on_indent(self, s):
        '''
        Split a line into its leading indentation and everything else.
        '''
        line = s.lstrip(self.indents_str)
        indent = s[:len(s)-len(line)]
        return (indent, line)


    def _build_parsing_dicts_and_re(self):
        _parse_line = {'':       self._parse_line_goto_next,
                       '(':      self._parse_line_open_paren,
                       '\uFF08': self._parse_line_open_paren,
                       ')':      self._parse_line_close_obj,
                       '\uFF09': self._parse_line_close_obj,
                      }
        self._parse_line = unicoding.keydefaultdict(lambda c: self._parse_line_string, _parse_line)

        na = re.escape(self.indents_str + '()\uFF08\uFF09')
        pattern = r'''( (?:\(|\uFF08)  # Opening parenthesis
                        [^{na}]*?  # Contents; don't worry about newlines cause can only be at end of string
                        (?:\)|\uFF09)  # Closing parenthesis
                        (?:>|\uFF1E)|)  # Greater-than sign
                   '''.format(na=na)
        self._explicit_type_re = re.compile(pattern, re.VERBOSE)



    def _parse_line_get_next(self):
        '''Get next line.  For use in lookahead in string scanning, etc.'''
        line = next(self._line_gen, None)
        self.source.end_lineno += 1
        return line

    def _parse_line_goto_next(self, line):
        '''Go to next line, after current parsing is complete.'''
        line = next(self._line_gen, None)
        self.source.start_lineno += 1
        self._at_line_start = True
        return line

    def _parse_line_open_paren(self, line):
        '''Handle opening parenthesis.'''
        m = self._explicit_type_re.match(line).group(0)
        if m:
            if not ((m[0] == '(' and m[-2:] == ')>') or (m[0] == '\uFF08' and m[-2:] == '\uFF09\uFF1E')):
                raise erring.ParseError('Mixing fullwidth and non-fullwidth parentheses and/or greater-than sign in type declaration', self.source)
            # All types should be defined using ASCII, but should be able to
            # invoke a type using fullwidth characters
            t = self.unicodefilter.fullwidth_to_halfwidth_ascii(m[1:-2])
            if t not in self.parsers:
                raise erring.ParseError('Unrecognized type declaration "{0}"'.format(m), self.source)
            self._next_type = t
            line = line[len(m):].lstrip(self.whitespace_str)
        else:
            self._ast_pos.check_append(AstObj(nodetype=self._next_type, cat=None, source=self.source, openchar=line[0]))
            # Reset typing
            self._next_type = None
            self._ast_pos_stack.append(self._ast_pos)
            self._ast_pos = self._ast_pos[-1]
            self._in_compact_stack.append(self._in_compact)
            self._in_compact = True
            line = line[1:].lstrip(self.whitespace_str)
        return line

    def _parse_line_close_paren(self, line):
        '''Handle closing parenthesis'''
        if self._ast_pos.closechar != line[0]:
            raise erring.ParseError('Collection closed by character "{0}" that does not pair with the character used to open it'.format(line[0]))
        try:
            self._ast_pos = self._ast_pos_stack.pop()
            self._in_compact = self._in_compact_stack.pop()
        except IndexError:
            raise erring.ParseError('Trying to close a collection that does not exist')
        return line[1:].lstrip(self.whitespace_str)

    def _parse_line_string(self, line):
        if line.startswith('"'):
            s = line.split('"', 2)
        self._ast_pos.append(s[1])
        return s[2].lstrip(self.whitespace_str)









'''
magic_number = '%!bespon'
if s.startswith(magic_number):
    s = s[len(magic_number):]
    if s.rstrip(self.whitespace_str):
        raise ValueError('Invalid first line, or unsupported parser directives:\n  {0}'.format(magic_number+s))
    s = ''
'''
